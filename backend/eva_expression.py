"""
Eva Expression System - Breathing, Emotions & Voice Modulation

Rend Eva vivante avec:
- Sons de respiration rÃ©els (audio)
- DÃ©tection d'Ã©motions dans le texte
- Modulation de la voix selon l'Ã©motion
- Animations suggÃ©rÃ©es pour l'avatar
"""

import numpy as np
import re
import random
from typing import Optional, Tuple, Dict, List
from dataclasses import dataclass
import io

# Import TTS for generating breathing sounds
try:
    from ultra_fast_tts import ultra_fast_tts, init_ultra_fast_tts
except ImportError:
    ultra_fast_tts = None


@dataclass
class Emotion:
    """ReprÃ©sente une Ã©motion dÃ©tectÃ©e."""
    name: str
    intensity: float  # 0.0 - 1.0
    voice_speed: float  # 0.8 - 1.3
    voice_pitch: int  # -5 to +5 semitones
    animation: str  # Animation suggÃ©rÃ©e pour l'avatar


# Ã‰motions supportÃ©es avec leurs paramÃ¨tres vocaux
EMOTIONS = {
    "joy": Emotion("joy", 0.8, 1.1, 2, "smile_big"),
    "excitement": Emotion("excitement", 0.9, 1.2, 3, "eyes_wide"),
    "tenderness": Emotion("tenderness", 0.7, 0.95, 1, "soft_smile"),
    "sadness": Emotion("sadness", 0.6, 0.85, -2, "sad_eyes"),
    "surprise": Emotion("surprise", 0.8, 1.15, 4, "eyebrows_up"),
    "curiosity": Emotion("curiosity", 0.6, 1.05, 1, "head_tilt"),
    "playful": Emotion("playful", 0.7, 1.1, 2, "wink"),
    "empathy": Emotion("empathy", 0.6, 0.9, 0, "nod_slow"),
    "thoughtful": Emotion("thoughtful", 0.5, 0.9, -1, "look_up"),
    "neutral": Emotion("neutral", 0.3, 1.0, 0, "idle"),
}

# Patterns pour dÃ©tecter les Ã©motions dans le texte
EMOTION_PATTERNS = {
    "joy": [
        r"\bhaha\b", r"\bhihi\b", r"\bmdr\b", r"j'adore", r"trop bien",
        r"gÃ©nial", r"super", r"cool", r"ðŸ˜Š", r"ðŸ˜„", r"â¤ï¸"
    ],
    "excitement": [
        r"!!+", r"waouh", r"oh la la", r"incroyable", r"dingue",
        r"trop hÃ¢te", r"j'ai hÃ¢te", r"QUOI"
    ],
    "tenderness": [
        r"mignon", r"adorable", r"tendresse", r"doux", r"cÃ¢lin",
        r"prends soin", r"je t'aime"
    ],
    "sadness": [
        r"triste", r"dommage", r"snif", r"dÃ©solÃ©e", r"malheureusement",
        r"ðŸ˜¢", r"ðŸ˜”", r"pfff"
    ],
    "surprise": [
        r"quoi\?!", r"sÃ©rieux\?", r"noooon", r"vraiment\?", r"attends",
        r"ðŸ˜®", r"ðŸ˜²"
    ],
    "curiosity": [
        r"raconte", r"dis-moi", r"comment", r"pourquoi", r"c'est quoi",
        r"ðŸ¤”", r"hmm"
    ],
    "playful": [
        r"taquine", r"coquin", r"ðŸ˜", r"ðŸ˜œ", r"hihi", r"voyons voir"
    ],
    "empathy": [
        r"je comprends", r"c'est dur", r"courage", r"lÃ  pour toi",
        r"Ã§a va aller"
    ],
    "thoughtful": [
        r"je pense", r"peut-Ãªtre", r"hmm", r"intÃ©ressant", r"rÃ©flÃ©chis"
    ],
}


class EvaExpressionSystem:
    """SystÃ¨me d'expression pour rendre Eva vivante."""

    def __init__(self):
        self._breathing_sounds: Dict[str, bytes] = {}
        self._emotion_sounds: Dict[str, bytes] = {}
        self._initialized = False

    def init(self) -> bool:
        """Initialise les sons de respiration et d'Ã©motion."""
        if self._initialized:
            return True

        if ultra_fast_tts is None:
            print("âš ï¸  Ultra-fast TTS not available for expression sounds")
            return False

        try:
            init_ultra_fast_tts()

            # GÃ©nÃ©rer les sons de respiration
            breathing_phrases = {
                "inhale": "hmm",
                "exhale_soft": "ah",
                "exhale_thinking": "mmh",
                "sigh": "pfff",
                "breath_pause": "...",
            }

            for name, phrase in breathing_phrases.items():
                audio = ultra_fast_tts(phrase, speed=0.8)
                if audio:
                    self._breathing_sounds[name] = audio

            # GÃ©nÃ©rer les sons d'Ã©motion/rÃ©action
            emotion_sounds = {
                "laugh_soft": "hihi",
                "laugh": "haha",
                "surprise": "oh",
                "interest": "ah",
                "thinking": "hmm",
                "agreement": "mmh mmh",
                "playful": "hÃ©hÃ©",
            }

            for name, phrase in emotion_sounds.items():
                audio = ultra_fast_tts(phrase, speed=1.0)
                if audio:
                    self._emotion_sounds[name] = audio

            self._initialized = True
            print(f"âœ… Eva Expression: {len(self._breathing_sounds)} breathing + {len(self._emotion_sounds)} emotion sounds")
            return True

        except Exception as e:
            print(f"âŒ Expression system init failed: {e}")
            return False

    def detect_emotion(self, text: str) -> Emotion:
        """DÃ©tecte l'Ã©motion dominante dans le texte."""
        text_lower = text.lower()
        scores = {}

        for emotion_name, patterns in EMOTION_PATTERNS.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, text_lower, re.IGNORECASE))
                score += matches
            if score > 0:
                scores[emotion_name] = score

        if not scores:
            return EMOTIONS["neutral"]

        # Retourner l'Ã©motion avec le score le plus Ã©levÃ©
        dominant = max(scores, key=scores.get)
        emotion = EMOTIONS[dominant]

        # Ajuster l'intensitÃ© selon le nombre de matches
        intensity = min(1.0, scores[dominant] / 3)
        return Emotion(
            emotion.name,
            intensity,
            emotion.voice_speed,
            emotion.voice_pitch,
            emotion.animation
        )

    def get_breathing_sound(self, context: str = "random") -> Optional[bytes]:
        """Retourne un son de respiration appropriÃ© au contexte."""
        if not self._breathing_sounds:
            return None

        if context == "before_speech":
            choices = ["inhale", "exhale_thinking"]
        elif context == "after_speech":
            choices = ["exhale_soft", "sigh"]
        elif context == "thinking":
            choices = ["exhale_thinking", "inhale"]
        else:
            choices = list(self._breathing_sounds.keys())

        available = [c for c in choices if c in self._breathing_sounds]
        if not available:
            return None

        return self._breathing_sounds[random.choice(available)]

    def get_emotion_sound(self, emotion: str) -> Optional[bytes]:
        """Retourne un son d'Ã©motion appropriÃ©."""
        if not self._emotion_sounds:
            return None

        mapping = {
            "joy": ["laugh_soft", "laugh"],
            "excitement": ["surprise", "interest"],
            "surprise": ["surprise", "interest"],
            "playful": ["playful", "laugh_soft"],
            "thoughtful": ["thinking"],
            "curiosity": ["interest", "thinking"],
        }

        choices = mapping.get(emotion, ["thinking"])
        available = [c for c in choices if c in self._emotion_sounds]
        if not available:
            return None

        return self._emotion_sounds[random.choice(available)]

    def get_voice_params(self, emotion: Emotion) -> Dict[str, str]:
        """Retourne les paramÃ¨tres de voix pour Edge-TTS selon l'Ã©motion."""
        # Convertir les paramÃ¨tres en format Edge-TTS
        speed_percent = int((emotion.voice_speed - 1.0) * 100)
        speed_str = f"+{speed_percent}%" if speed_percent >= 0 else f"{speed_percent}%"

        pitch_str = f"+{emotion.voice_pitch}Hz" if emotion.voice_pitch >= 0 else f"{emotion.voice_pitch}Hz"

        return {
            "rate": speed_str,
            "pitch": pitch_str,
        }

    def get_animation_suggestion(self, text: str) -> List[Dict]:
        """SuggÃ¨re des animations basÃ©es sur le texte."""
        emotion = self.detect_emotion(text)
        animations = []

        # Animation de base selon l'Ã©motion
        animations.append({
            "type": emotion.animation,
            "intensity": emotion.intensity,
            "duration": 0.5
        })

        # Animations additionnelles selon le contenu
        if "?" in text:
            animations.append({"type": "head_tilt", "intensity": 0.5, "duration": 0.3})

        if "!" in text:
            animations.append({"type": "eyebrows_up", "intensity": 0.6, "duration": 0.2})

        if any(w in text.lower() for w in ["non", "pas", "jamais"]):
            animations.append({"type": "head_shake", "intensity": 0.4, "duration": 0.4})

        if any(w in text.lower() for w in ["oui", "ouais", "bien sÃ»r"]):
            animations.append({"type": "nod", "intensity": 0.5, "duration": 0.3})

        return animations

    def process_for_expression(self, text: str) -> Dict:
        """Traite le texte et retourne toutes les infos d'expression."""
        emotion = self.detect_emotion(text)

        return {
            "emotion": emotion.name,
            "intensity": emotion.intensity,
            "voice_params": self.get_voice_params(emotion),
            "animations": self.get_animation_suggestion(text),
            "breathing_before": self.get_breathing_sound("before_speech"),
            "breathing_after": self.get_breathing_sound("after_speech"),
        }


# Instance globale
eva_expression = EvaExpressionSystem()


# Fonctions utilitaires
def init_expression_system() -> bool:
    """Initialise le systÃ¨me d'expression."""
    return eva_expression.init()


def detect_emotion(text: str) -> Emotion:
    """DÃ©tecte l'Ã©motion dans le texte."""
    return eva_expression.detect_emotion(text)


def get_expression_data(text: str) -> Dict:
    """Retourne toutes les donnÃ©es d'expression pour un texte."""
    return eva_expression.process_for_expression(text)


if __name__ == "__main__":
    # Test
    init_expression_system()

    test_texts = [
        "Haha, trop bien ! J'adore Ã§a !",
        "Oh non, c'est triste...",
        "Attends... QUOI ?! SÃ©rieux ?",
        "Hmm, c'est intÃ©ressant ce que tu dis...",
        "Raconte-moi tout ! Je veux savoir !",
    ]

    for text in test_texts:
        emotion = detect_emotion(text)
        print(f"'{text[:40]}...'")
        print(f"  â†’ Emotion: {emotion.name} ({emotion.intensity:.1f})")
        print(f"  â†’ Voice: speed={emotion.voice_speed}, pitch={emotion.voice_pitch}")
        print(f"  â†’ Animation: {emotion.animation}")
        print()
